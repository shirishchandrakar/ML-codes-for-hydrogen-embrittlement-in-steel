{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d00ab8dc-9495-41db-9780-0357d1e113f7",
   "metadata": {},
   "source": [
    "Input Properties Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f0a9f2-9657-4023-9ee4-ab4262a50111",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing all the required libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from itertools import combinations\n",
    "from pandas import DataFrame\n",
    "import sklearn\n",
    "from pandas import DataFrame\n",
    "from matplotlib import pyplot\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import seaborn as sns\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import random\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn import metrics\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50082e53-c5ce-474a-bcc3-afc47efe8e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset\n",
    "\n",
    "dataset=pd.read_csv(r\"HEI New.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5e50ae-37ed-4db0-add0-c58d4e70e5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalising datapoints\n",
    "\n",
    "df=dataset[[\"Fe\",\"Mn\",\"Ni\",\"Ti\",\"Mo\",\"N\",\"S\",\"C\",\"Al\",\"Si\",\"Nb\",\"Cu\",\"V\",\"Cr\",\"P\",\"Grain size\", \"HEI\",\"current density/Pressure\",\"Time\",\"Strain rate\",\t\"Ion Radius_Avg\", \"Bulk Modulus_Avg\",\t\t\"Shear Modulus_Avg\",\t\"Effective nuclear charge_Avg\",\t\t\"Valence electron Concentration_Avg\",\"Allen Electronegativity_Avg\",\"Cohesive energy_Avg\"]]\n",
    "df1=dataset[[\"Fe\",\"Mn\",\"Ni\",\"Ti\",\"Mo\",\"N\",\"S\",\"C\",\"Al\",\"Si\",\"Nb\",\"Cu\",\"V\",\"Cr\",\"P\",\"Grain size\", \"HEI\",\"current density/Pressure\",\t\"Time\",\t\"Strain rate\",\t\"YS\",\t\"UTS\",\t\"UTS ductility\",\"Fracture ductility\",\"Ion Radius_Avg\", \"Bulk Modulus_Avg\",\"Shear Modulus_Avg\",\"Effective nuclear charge_Avg\",\"Valence electron Concentration_Avg\",\"Allen Electronegativity_Avg\",\"Cohesive energy_Avg\"]]\n",
    "\n",
    "from sklearn import preprocessing\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(df)\n",
    "df_normalized = pd.DataFrame(x_scaled)\n",
    "\n",
    "#Saving normalised datapoints into \n",
    "df_normalized.to_csv(r\"Regression_NewNormalisedElectrochargingPropertyData_InputProperties.csv\", header = [\"Fe\",\"Mn\",\"Ni\",\"Ti\",\"Mo\",\"N\",\"S\",\"C\",\"Al\",\"Si\",\"Nb\",\"Cu\",\"V\",\"Cr\",\"P\",\"Grain size\",\"HEI\", \"current density/Pressure\",\t\"Time\",\t\"Strain rate\",\"Ion Radius_Avg\", \"Bulk Modulus_Avg\",\"Shear Modulus_Avg\",\"Effective nuclear charge_Avg\",\"Valence electron Concentration_Avg\",\"Allen Electronegativity_Avg\",\"Cohesive energy_Avg\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333879c7-0cd0-415a-b265-4f0fc4d32fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Input = pd.read_csv(r\"Regression_NewNormalisedElectrochargingPropertyData_InputProperties.csv\", header = 0)\n",
    "x = Input.loc[:, [\"Fe\",\"Mn\",\"Ni\",\"Ti\",\"Mo\",\"N\",\"S\",\"C\",\"Al\",\"Si\",\"Nb\",\"Cu\",\"V\",\"Cr\",\"P\",\"Grain size\", \"current density/Pressure\",\t\"Time\",\t\"Strain rate\",\"Ion Radius_Avg\", \"Bulk Modulus_Avg\",\"Shear Modulus_Avg\",\"Effective nuclear charge_Avg\",\"Valence electron Concentration_Avg\",\"Allen Electronegativity_Avg\",\"Cohesive energy_Avg\"]]\n",
    "y= df1.loc[:, [\"HEI\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fdd9f35-aa4e-41ee-81d4-3b360ae3db2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting heatmap\n",
    "\n",
    "plt.figure(figsize=(120, 100))  # Set the size of the figure\n",
    "sns.heatmap(x.corr(), cmap=\"viridis\", annot=True, annot_kws={\"fontsize\": 64})  # Set the fontsize parameter\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc5ea8f-7e6d-432e-861e-042bda683640",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Importance Score calculation using Gradient Boosting \n",
    "\n",
    "gb_reg = GradientBoostingRegressor(loss= 'squared_error', learning_rate=0.1, n_estimators=100, max_depth=3)\n",
    "gb_reg.fit(x,y.values.ravel())\n",
    "feature_importances= gb_reg.feature_importances_\n",
    "\n",
    "for feature_name, importance_score in zip(x.columns, feature_importances):\n",
    "    print(f\"{feature_name}: {importance_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4fd1d9d-0461-420d-b258-efe386a75300",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ploting Feature Imposrtance Score\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(x.columns, feature_importances)\n",
    "plt.xlabel('Feature Importance Score')\n",
    "plt.ylabel('Features')\n",
    "plt.title('Feature Importances')\n",
    "plt.gca().invert_yaxis()  # Invert y-axis to display most important feature on top\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89fd53e3-7d6b-43ae-9f6f-aadf904f1418",
   "metadata": {},
   "source": [
    "Model Training for UTS Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f7bfba-95fc-4355-a21b-bbec51a6acb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Input = pd.read_csv(r\"Regression_NewNormalisedElectrochargingPropertyData_InputProperties.csv\", header = 0)\n",
    "x = Input.loc[:, [\"Fe\",\"Mn\",\"Ni\",\"Ti\",\"Mo\",\"N\",\"S\",\"C\",\"Al\",\"Si\",\"Nb\",\"Cu\",\"V\",\"Cr\",\"P\",\"Grain size\", \"current density/Pressure\",\t\"Time\",\t\"Strain rate\",\"Ion Radius_Avg\", \"Bulk Modulus_Avg\",\"Shear Modulus_Avg\",\"Effective nuclear charge_Avg\",\"Valence electron Concentration_Avg\",\"Allen Electronegativity_Avg\",\"Cohesive energy_Avg\"]]\n",
    "y1= df1.loc[:, [\"UTS\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0eb452-6ac5-44eb-81d5-5d03c4e00218",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting into test and train datapoints\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y1, random_state =42 ,test_size = 0.2)\n",
    "\n",
    "# Define the pipelines\n",
    "pipelines = []\n",
    "pipelines.append(('ScaledLR', Pipeline([('Scaler', StandardScaler()), ('LR', LinearRegression())])))\n",
    "pipelines.append(('ScaledKNN', Pipeline([('Scaler', StandardScaler()), ('KNN', KNeighborsRegressor())])))\n",
    "pipelines.append(('ScaledGBM', Pipeline([('Scaler', StandardScaler()), ('GBM', GradientBoostingRegressor())])))\n",
    "pipelines.append(('ScaledLASSO', Pipeline([('Scaler', StandardScaler()), ('LASSO', Lasso())])))\n",
    "pipelines.append(('ScaledEN', Pipeline([('Scaler', StandardScaler()), ('EN', ElasticNet())])))\n",
    "pipelines.append(('ScaledCART', Pipeline([('Scaler', StandardScaler()), ('CART', DecisionTreeRegressor())])))\n",
    "\n",
    "results = []\n",
    "names = []\n",
    "r2_scores = []\n",
    "\n",
    "# Evaluate each model using cross-validation\n",
    "for name, model in pipelines:\n",
    "    kfold = KFold(n_splits=10, random_state=42, shuffle=True)\n",
    "    cv_results = cross_val_score(model, x_train, y_train, cv=kfold, scoring='r2')\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    r2_mean = cv_results.mean()\n",
    "    r2_scores.append(r2_mean)\n",
    "    print(f\"{name}: R2 score mean: {r2_mean}\")\n",
    "\n",
    "# Find the best performing model\n",
    "best_model_idx = np.argmax(r2_scores)\n",
    "best_model_name = names[best_model_idx]\n",
    "best_model_r2 = r2_scores[best_model_idx]\n",
    "print(f\"\\nBest performing model: {best_model_name} with R2 score mean: {best_model_r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10057518-7b32-4f54-9e6c-1334992ef42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape y1_train and y1_test into 1D arrays \n",
    "y1_train = np.ravel(y_train)\n",
    "y1_test = np.ravel(y_test)\n",
    "\n",
    "# create the pipeline object\n",
    "rf_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('rf_regressor', RandomForestRegressor(n_estimators=100, random_state=42))\n",
    "])\n",
    "\n",
    "# fit the pipeline to the training data\n",
    "rf_pipeline.fit(x_train, y1_train)\n",
    "\n",
    "# Extract feature importances\n",
    "feature_importances = rf_pipeline.named_steps['rf_regressor'].feature_importances_\n",
    "\n",
    "# Extract the coefficients (feature importances) and intercept\n",
    "coefficients = feature_importances\n",
    "# Create a dummy input array with zeros for calculating the intercept\n",
    "dummy_input = np.zeros((1, len(x_train.columns))) if isinstance(x_train, pd.DataFrame) else np.zeros((1, len(x_train[0])))\n",
    "intercept = rf_pipeline.named_steps['rf_regressor'].predict(dummy_input)[0]\n",
    "\n",
    "# Print the equation\n",
    "print(\"Equation:\")\n",
    "equation = \" + \".join([f\"{coeff:.4f} * x{i+1}\" for i, coeff in enumerate(coefficients)])\n",
    "print(f\"y = {equation} + {intercept:.4f}\")\n",
    "\n",
    "# make predictions on the test set\n",
    "y1_pred = rf_pipeline.predict(x_test)\n",
    "\n",
    "# calculate the R2 score\n",
    "r2 = r2_score(y1_test, y1_pred)\n",
    "\n",
    "# print the R2 score\n",
    "print(f\"R2 score: {r2:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9cb3f6-f64d-4db8-be6d-3e13703163c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate Scoring metrics \n",
    "\n",
    "y1_pred_test_EN = rf_pipeline.predict(x_test)\n",
    "y1_pred_train_EN = rf_pipeline.predict(x_train)\n",
    "\n",
    "r2_train = metrics.r2_score(y_train, y1_pred_train_EN)\n",
    "adj_r2_train = 1 - (1-r2_train)*(len(x_train)-1)/(len(x_train)-df.shape[1]-1)\n",
    "r2_test = metrics.r2_score(y_test, y1_pred_test_EN)\n",
    "adj_r2_test = 1 - (1-r2_test)*(len(x_train)-1)/(len(x_train)-df.shape[1]-1)\n",
    "\n",
    "\n",
    "print('For Train: ')\n",
    "print('R squared value:', metrics.r2_score(y_train, y1_pred_train_EN))\n",
    "print('Adjusted R2Score: ', adj_r2_train)\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_train, y1_pred_train_EN))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_train, y1_pred_train_EN))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_train, y1_pred_train_EN)))\n",
    "#print('Mean Relative Error:', mre_train)\n",
    "print('For Test: ')\n",
    "print('R squared value:', metrics.r2_score(y_test, y1_pred_test_EN))\n",
    "print('Adjusted R2Score: ', adj_r2_test)\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y1_pred_test_EN))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y1_pred_test_EN))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y1_pred_test_EN)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d926d27c-295d-4a93-81c7-d2a121d2fe8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"y_test:\", y1_test)\n",
    "print(\"y_pred:\", y1_pred)\n",
    "\n",
    "# Save y_test and y_pred to a CSV file\n",
    "with open('utsdata.csv', mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['y_test', 'y_pred'])\n",
    "    for yt, yp in zip(y1_test, y1_pred):\n",
    "        writer.writerow([yt, yp])\n",
    "\n",
    "# Plotting Reported Vs Predicted\n",
    "plt.scatter(y1_pred, y1_test)\n",
    "plt.plot(y1_pred, y1_test)\n",
    "plt.xlabel('Predicted UTS')\n",
    "plt.ylabel('Actual UTS')\n",
    "plt.title('UTS')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d280f599-b59c-4573-843b-57bba51d8523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the SHAP explainer with the trained Random Forest Regressor model\n",
    "explainer = shap.Explainer(rf_pipeline.named_steps['rf_regressor'], x_train)\n",
    "\n",
    "# Calculate SHAP values for all samples in the test set\n",
    "shap_values = explainer.shap_values(x_test)\n",
    "\n",
    "# Calculate mean SHAP values for each property\n",
    "mean_shap_values = shap_values.mean(axis=0)\n",
    "\n",
    "# Print mean SHAP values for each property\n",
    "for property_name, mean_shap_value in zip(x_train.columns, mean_shap_values):\n",
    "    print(f\"Mean SHAP Value for {property_name}: {mean_shap_value}\")\n",
    "\n",
    "# Summarize the impact of all features (bar plot)\n",
    "shap.summary_plot(shap_values, x_test, plot_type='bar', feature_names=x_train.columns)\n",
    "\n",
    "# Summarize the impact of all features\n",
    "shap.summary_plot(shap_values, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a958dc-d82d-4ae8-b361-61093ee8c053",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training GBR model\n",
    "GBR = GradientBoostingRegressor()\n",
    "parameters = {'learning_rate': [0.01,0.02,0.03,0.04],\n",
    "                  'subsample'    : [0.9, 0.5, 0.2, 0.1],\n",
    "                  'n_estimators' : [100,500,1000, 1500],\n",
    "                  'max_depth'    : [4,6,8,10]\n",
    "                 }\n",
    "grid_GBR = GridSearchCV(estimator=GBR, param_grid = parameters, cv = 2, n_jobs=-1)\n",
    "grid_GBR.fit(x_train, y_train)\n",
    "\n",
    "print(\" Results from Grid Search \" )\n",
    "print(\"\\n The best estimator across ALL searched params:\\n\",grid_GBR.best_estimator_)\n",
    "print(\"\\n The best score across ALL searched params:\\n\",grid_GBR.best_score_)\n",
    "print(\"\\n The best parameters across ALL searched params:\\n\",grid_GBR.best_params_)\n",
    "\n",
    "gbr = GradientBoostingRegressor(n_estimators=100, learning_rate=0.04, max_depth=6, subsample=0.2)\n",
    "gbr.fit(x_train, y_train)\n",
    "\n",
    "pred_y1 = gbr.predict(x_test)\n",
    "\n",
    "R2 = r2_score(pred_y1, y_test)\n",
    "print(f\"R2: {R2:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce132ef-6ffa-4cc4-a962-f21d1e5657a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Elastic Net Training\n",
    "\n",
    "# Define the pipeline with polynomial features and elastic net\n",
    "pipeline = Pipeline([\n",
    "    ('poly', PolynomialFeatures(degree=3)),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('elasticnet', ElasticNet(max_iter=1000000))\n",
    "])\n",
    "\n",
    "# Define the hyperparameter grid to search over\n",
    "param_grid = {\n",
    "    'elasticnet__alpha': [0.01, 0.05, 0.08, 0.09, 0.1, 0.5, 1.0, 10.0, 100.0],\n",
    "    'elasticnet__l1_ratio': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "}\n",
    "\n",
    "# Define the GridSearchCV object to run the search\n",
    "grid_search = GridSearchCV(pipeline, param_grid=param_grid, cv=5, scoring='r2', n_jobs=-1)\n",
    "\n",
    "# Fit the model on the training data\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters and score\n",
    "print(\"Best hyperparameters: \", grid_search.best_params_)\n",
    "print(\"Best score: \", grid_search.best_score_)\n",
    "\n",
    "# Get the predictions on the test data\n",
    "y_pred = grid_search.predict(x_test)\n",
    "\n",
    "# Get the R2 score on the test data\n",
    "r2_score = r2_score(y_test, y_pred)\n",
    "print(\"R2 score on test data: \", r2_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554a250d-9621-4eb9-ba76-7a3d98ca4686",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Elastic Net Regressor:- ')\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "print(\"Cross-validation score:{}\".format(grid_search.best_score_))\n",
    "print(\"\")\n",
    "\n",
    "y_pred_test_EN = grid_search.predict(x_test)\n",
    "y_pred_train_EN = grid_search.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c1f557-4bcf-4ec7-9ecb-57d2213f7f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_train = metrics.r2_score(y_train, y_pred_train_EN)\n",
    "adj_r2_train = 1 - (1-r2_train)*(len(x_train)-1)/(len(x_train)-df.shape[1]-1)\n",
    "r2_test = metrics.r2_score(y_test, y_pred_test_EN)\n",
    "adj_r2_test = 1 - (1-r2_test)*(len(x_train)-1)/(len(x_train)-df.shape[1]-1)\n",
    "\n",
    "\n",
    "print('For Train: ')\n",
    "print('R squared value:', metrics.r2_score(y_train, y_pred_train_EN))\n",
    "print('Adjusted R2Score: ', adj_r2_train)\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_train, y_pred_train_EN))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_train, y_pred_train_EN))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_train, y_pred_train_EN)))\n",
    "#print('Mean Relative Error:', mre_train)\n",
    "print('For Test: ')\n",
    "print('R squared value:', metrics.r2_score(y_test, y_pred_test_EN))\n",
    "print('Adjusted R2Score: ', adj_r2_test)\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred_test_EN))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred_test_EN))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred_test_EN)))\n",
    "#print('Mean Relative Error:', mre_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97c1cc5-d8bc-4076-9c02-7d507531350a",
   "metadata": {},
   "source": [
    "Model Training for Ductility Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72cb674f-21a2-480d-ae6b-b87c081dd785",
   "metadata": {},
   "outputs": [],
   "source": [
    "Input = pd.read_csv(r\"Regression_NewNormalisedElectrochargingPropertyData_InputProperties.csv\", header = 0)\n",
    "x = Input.loc[:, [\"Fe\",\"Mn\",\"Ni\",\"Ti\",\"Mo\",\"N\",\"S\",\"C\",\"Al\",\"Si\",\"Nb\",\"Cu\",\"V\",\"Cr\",\"P\",\"Grain size\", \"current density/Pressure\",\t\"Time\",\t\"Strain rate\",\"Ion Radius_Avg\", \"Bulk Modulus_Avg\",\"Shear Modulus_Avg\",\"Effective nuclear charge_Avg\",\"Valence electron Concentration_Avg\",\"Allen Electronegativity_Avg\",\"Cohesive energy_Avg\"]]\n",
    "y2= df1.loc[:, [\"UTS Ductility\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fd6e68-fd86-4f45-9e70-eecba9f0df06",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y2_train, y2_test = train_test_split(x, y2, random_state =42 ,test_size = 0.2)\n",
    "\n",
    "# Define the pipelines\n",
    "pipelines = []\n",
    "pipelines.append(('ScaledLR', Pipeline([('Scaler', StandardScaler()), ('LR', LinearRegression())])))\n",
    "pipelines.append(('ScaledKNN', Pipeline([('Scaler', StandardScaler()), ('KNN', KNeighborsRegressor())])))\n",
    "pipelines.append(('ScaledGBM', Pipeline([('Scaler', StandardScaler()), ('GBM', GradientBoostingRegressor())])))\n",
    "pipelines.append(('ScaledLASSO', Pipeline([('Scaler', StandardScaler()), ('LASSO', Lasso())])))\n",
    "pipelines.append(('ScaledEN', Pipeline([('Scaler', StandardScaler()), ('EN', ElasticNet())])))\n",
    "pipelines.append(('ScaledCART', Pipeline([('Scaler', StandardScaler()), ('CART', DecisionTreeRegressor())])))\n",
    "\n",
    "results = []\n",
    "names = []\n",
    "r2_scores = []\n",
    "\n",
    "# Evaluate each model using cross-validation\n",
    "for name, model in pipelines:\n",
    "    kfold = KFold(n_splits=10, random_state=42, shuffle=True)\n",
    "    cv_results = cross_val_score(model, x_train, y2_train, cv=kfold, scoring='r2')\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    r2_mean = cv_results.mean()\n",
    "    r2_scores.append(r2_mean)\n",
    "    print(f\"{name}: R2 score mean: {r2_mean}\")\n",
    "\n",
    "# Find the best performing model\n",
    "best_model_idx = np.argmax(r2_scores)\n",
    "best_model_name = names[best_model_idx]\n",
    "best_model_r2 = r2_scores[best_model_idx]\n",
    "print(f\"\\nBest performing model: {best_model_name} with R2 score mean: {best_model_r2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072dbc42-8269-4f54-8fbd-9433dc347d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y2_train = np.ravel(y2_train)\n",
    "y2_test = np.ravel(y2_test)\n",
    "\n",
    "# create the pipeline object\n",
    "rf_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('rf_regressor', RandomForestRegressor(n_estimators=100, random_state=42))\n",
    "])\n",
    "\n",
    "# fit the pipeline to the training data\n",
    "rf_pipeline.fit(x_train, y2_train)\n",
    "\n",
    "# Extract feature importances\n",
    "feature_importances = rf_pipeline.named_steps['rf_regressor'].feature_importances_\n",
    "\n",
    "# Extract the coefficients (feature importances) and intercept\n",
    "coefficients = feature_importances\n",
    "# Create a dummy input array with zeros for calculating the intercept\n",
    "dummy_input = np.zeros((1, len(x_train.columns))) if isinstance(x_train, pd.DataFrame) else np.zeros((1, len(x_train[0])))\n",
    "intercept = rf_pipeline.named_steps['rf_regressor'].predict(dummy_input)[0]\n",
    "\n",
    "# Print the equation\n",
    "print(\"Equation:\")\n",
    "equation = \" + \".join([f\"{coeff:.4f} * x{i+1}\" for i, coeff in enumerate(coefficients)])\n",
    "print(f\"y = {equation} + {intercept:.4f}\")\n",
    "\n",
    "# make predictions on the test set\n",
    "y2_pred = rf_pipeline.predict(x_test)\n",
    "\n",
    "# calculate the R2 score\n",
    "r2 = r2_score(y2_test, y2_pred)\n",
    "\n",
    "# print the R2 score\n",
    "print(f\"R2 score: {r2:.3f}\")\n",
    "\n",
    "\n",
    "# make predictions on the test set\n",
    "y2_pred = rf_pipeline.predict(x_test)\n",
    "\n",
    "# calculate the MAE value\n",
    "mae = mean_absolute_error(y2_test, y2_pred)\n",
    "\n",
    "# print the MAE value\n",
    "print(f\"MAE value: {mae:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce3f72b-aeba-4257-9a86-c050519f9355",
   "metadata": {},
   "outputs": [],
   "source": [
    "y2_pred_test_EN = rf_pipeline.predict(x_test)\n",
    "y2_pred_train_EN = rf_pipeline.predict(x_train)\n",
    "\n",
    "r2_train = metrics.r2_score(y2_train, y2_pred_train_EN)\n",
    "adj_r2_train = 1 - (1-r2_train)*(len(x_train)-1)/(len(x_train)-df.shape[1]-1)\n",
    "r2_test = metrics.r2_score(y2_test, y2_pred_test_EN)\n",
    "adj_r2_test = 1 - (1-r2_test)*(len(x_train)-1)/(len(x_train)-df.shape[1]-1)\n",
    "\n",
    "\n",
    "print('For Train: ')\n",
    "print('R squared value:', metrics.r2_score(y2_train, y2_pred_train_EN))\n",
    "print('Adjusted R2Score: ', adj_r2_train)\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y2_train, y2_pred_train_EN))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y2_train, y2_pred_train_EN))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y2_train, y2_pred_train_EN)))\n",
    "#print('Mean Relative Error:', mre_train)\n",
    "print('For Test: ')\n",
    "print('R squared value:', metrics.r2_score(y2_test, y2_pred_test_EN))\n",
    "print('Adjusted R2Score: ', adj_r2_test)\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y2_test, y2_pred_test_EN))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y2_test, y2_pred_test_EN))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y2_test, y2_pred_test_EN)))\n",
    "#print('Mean Relative Error:', mre_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9624090b-5fdd-409f-9ee3-0c2a623cbbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print y_test and y_pred\n",
    "print(\"y2_test:\", y2_test)\n",
    "print(\"y2_pred:\", y2_pred)\n",
    "\n",
    "# Save y_test and y_pred to a CSV file\n",
    "with open('utsductilitydata.csv', mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['y2_test', 'y2_pred'])\n",
    "    for yt, yp in zip(y2_test, y2_pred):\n",
    "        writer.writerow([yt, yp])\n",
    "\n",
    "# Plot\n",
    "plt.scatter(y2_pred, y2_test)\n",
    "plt.plot(y2_pred, y2_test)\n",
    "plt.xlabel('Predicted UTS')\n",
    "plt.ylabel('Actual UTS')\n",
    "plt.title('UTS')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b6e438-8d7c-45d5-a3f8-9e164f4a23bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the SHAP explainer with the trained Random Forest Regressor model\n",
    "explainer = shap.Explainer(rf_pipeline.named_steps['rf_regressor'], x_train)\n",
    "\n",
    "# Calculate SHAP values for all samples in the test set\n",
    "shap_values = explainer.shap_values(x_test)\n",
    "\n",
    "# Calculate mean SHAP values for each property\n",
    "mean_shap_values = shap_values.mean(axis=0)\n",
    "\n",
    "# Print mean SHAP values for each property\n",
    "for property_name, mean_shap_value in zip(x_train.columns, mean_shap_values):\n",
    "    print(f\"Mean SHAP Value for {property_name}: {mean_shap_value}\")\n",
    "\n",
    "# Summarize the impact of all features (bar plot)\n",
    "shap.summary_plot(shap_values, x_test, plot_type='bar', feature_names=x_train.columns)\n",
    "\n",
    "# Summarize the impact of all features\n",
    "shap.summary_plot(shap_values, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925995e0-6b51-47de-87ff-63807d62b763",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gradient Boosting Model Training\n",
    "GBR = GradientBoostingRegressor()\n",
    "parameters = {'learning_rate': [0.01,0.02,0.03,0.04],\n",
    "                  'subsample'    : [0.9, 0.5, 0.2, 0.1],\n",
    "                  'n_estimators' : [100,500,1000, 1500],\n",
    "                  'max_depth'    : [4,6,8,10]\n",
    "                 }\n",
    "grid_GBR = GridSearchCV(estimator=GBR, param_grid = parameters, cv = 2, n_jobs=-1)\n",
    "grid_GBR.fit(x_train, y2_train)\n",
    "\n",
    "print(\" Results from Grid Search \" )\n",
    "print(\"\\n The best estimator across ALL searched params:\\n\",grid_GBR.best_estimator_)\n",
    "print(\"\\n The best score across ALL searched params:\\n\",grid_GBR.best_score_)\n",
    "print(\"\\n The best parameters across ALL searched params:\\n\",grid_GBR.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa61172-a6b8-4755-b031-5409693417c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr = GradientBoostingRegressor(n_estimators=100, learning_rate=0.04, max_depth=6, subsample=0.2)\n",
    "gbr.fit(x_train, y2_train)\n",
    "\n",
    "pred_y1 = gbr.predict(x_test)\n",
    "\n",
    "R2 = r2_score(y2_pred, y2_test)\n",
    "print(f\"R2: {R2:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5837b3-826d-4c6e-bf11-6523dc7d9815",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the pipeline with polynomial features and elastic net\n",
    "pipeline = Pipeline([\n",
    "    ('poly', PolynomialFeatures(degree=3)),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('elasticnet', ElasticNet(max_iter=1000000))\n",
    "])\n",
    "\n",
    "# Define the hyperparameter grid to search over\n",
    "param_grid = {\n",
    "    'elasticnet__alpha': [0.01, 0.05, 0.08, 0.09, 0.1, 0.5, 1.0, 10.0, 100.0],\n",
    "    'elasticnet__l1_ratio': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "}\n",
    "\n",
    "# Define the GridSearchCV object to run the search\n",
    "grid_search = GridSearchCV(pipeline, param_grid=param_grid, cv=5, scoring='r2', n_jobs=-1)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y2, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit the model on the training data\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters and score\n",
    "print(\"Best hyperparameters: \", grid_search.best_params_)\n",
    "print(\"Best score: \", grid_search.best_score_)\n",
    "\n",
    "# Get the predictions on the test data\n",
    "y_pred = grid_search.predict(x_test)\n",
    "\n",
    "# Get the R2 score on the test data\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"R2 score on test data: \", r2)\n",
    "\n",
    "# Initialize the SHAP explainer with the trained Elastic Net model\n",
    "explainer = shap.Explainer(grid_search.best_estimator_.named_steps['elasticnet'], x_train)\n",
    "\n",
    "# Calculate SHAP values for all samples in the test set\n",
    "shap_values = explainer.shap_values(x_test)\n",
    "\n",
    "# Summarize the impact of all features\n",
    "shap.summary_plot(shap_values, x_test, plot_type='bar', feature_names=x_train.columns)\n",
    "\n",
    "# Display the SHAP values for individual predictions (you can choose specific instances)\n",
    "shap.summary_plot(shap_values, x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624036a1-1aa5-4db1-9139-9795b63e684b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Elastic Net Regressor:- ')\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "print(\"Cross-validation score:{}\".format(grid_search.best_score_))\n",
    "print(\"\")\n",
    "\n",
    "y2_pred_test_EN = grid_search.predict(x_test)\n",
    "y2_pred_train_EN = grid_search.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd1f58f-9b9e-4ac1-8e6c-9259c90753da",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_train = metrics.r2_score(y_train, y2_pred_train_EN)\n",
    "adj_r2_train = 1 - (1-r2_train)*(len(x_train)-1)/(len(x_train)-df.shape[1]-1)\n",
    "r2_test = metrics.r2_score(y_test, y2_pred_test_EN)\n",
    "adj_r2_test = 1 - (1-r2_test)*(len(x_train)-1)/(len(x_train)-df.shape[1]-1)\n",
    "\n",
    "\n",
    "print('For Train: ')\n",
    "print('R squared value:', metrics.r2_score(y_train, y2_pred_train_EN))\n",
    "print('Adjusted R2Score: ', adj_r2_train)\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_train, y2_pred_train_EN))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_train, y2_pred_train_EN))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_train, y2_pred_train_EN)))\n",
    "#print('Mean Relative Error:', mre_train)\n",
    "print('For Test: ')\n",
    "print('R squared value:', metrics.r2_score(y_test, y2_pred_test_EN))\n",
    "print('Adjusted R2Score: ', adj_r2_test)\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y2_pred_test_EN))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y2_pred_test_EN))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y2_pred_test_EN)))\n",
    "#print('Mean Relative Error:', mre_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
